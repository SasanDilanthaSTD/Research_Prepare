{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create operational functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- calculate_vegetation_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vegetation_indices(red, green, blue, nir):\n",
    "    \"\"\"Calculates various vegetation indices.\"\"\"\n",
    "    # NDVI\n",
    "    ndvi = (nir - red) / (nir + red + 1e-8)\n",
    "    # GRVI (Green-Red Vegetation Index)\n",
    "    grvi = (green - red) / (green + red + 1e-8)\n",
    "    # NDWI (Normalized Difference Water Index) -  NDWI = (Green - NIR) / (Green + NIR)\n",
    "    ndwi = (green - nir) / (green + nir + 1e-8)\n",
    "    # EVI (Enhanced Vegetation Index) - EVI = 2.5 * (NIR - Red) / (NIR + 6 * Red - 7.5 * Blue + 1)\n",
    "    evi = 2.5 * (nir - red) / (nir + 6 * red - 7.5 * blue + 1 + 1e-8)\n",
    "    return ndvi, grvi, ndwi, evi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- load_and_extract_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_extract_patches(stage_dir, patch_size=(64, 64)):\n",
    "    \"\"\"Loads GeoTIFFs, calculates vegetation indices, and extracts patches.\"\"\"\n",
    "    try:\n",
    "        with rasterio.open(os.path.join(stage_dir, \"red.tif\")) as src:\n",
    "            red = src.read(1).astype(np.float32)\n",
    "        with rasterio.open(os.path.join(stage_dir, \"green.tif\")) as src:\n",
    "            green = src.read(1).astype(np.float32)\n",
    "        with rasterio.open(os.path.join(stage_dir, \"blue.tif\")) as src:\n",
    "            blue = src.read(1).astype(np.float32)\n",
    "        with rasterio.open(os.path.join(stage_dir, \"nir.tif\")) as src:\n",
    "            nir = src.read(1).astype(np.float32)\n",
    "\n",
    "        features = calculate_vegetation_indices(red, green, blue, nir)\n",
    "\n",
    "        patches = []\n",
    "        height, width = features.shape[:2]\n",
    "        for i in range(0, height - patch_size[0] + 1, patch_size[0]):\n",
    "            for j in range(0, width - patch_size[1] + 1, patch_size[1]):\n",
    "                patches.append(features[i:i+patch_size[0], j:j+patch_size[1]])\n",
    "\n",
    "        return patches\n",
    "    except rasterio.RasterioIOError as e:\n",
    "        print(f\"Error loading image: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 01. Image path setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    data_dir = Path('../Data')\n",
    "    germination_patches = load_and_extract_patches(os.path.join(data_dir, \"germination\"))\n",
    "    tillering_patches = load_and_extract_patches(os.path.join(data_dir, \"tillering\"))\n",
    "    grand_growth_patches = load_and_extract_patches(os.path.join(data_dir, \"grand_growth\"))\n",
    "    ripening_patches = load_and_extract_patches(os.path.join(data_dir, \"ripening\"))\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2. Label Creat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "germination_labels = [0] * len(germination_patches)\n",
    "tillering_labels = [1] * len(tillering_patches)\n",
    "grand_growth_labels = [2] * len(grand_growth_patches)\n",
    "ripening_labels = [3] * len(ripening_patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 3. Image and lable combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patches = germination_patches + tillering_patches + grand_growth_patches + ripening_patches\n",
    "all_labels = germination_labels + tillering_labels + grand_growth_labels + ripening_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 4. Array Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patches = np.array(all_patches)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "\n",
    "# Handle cases where a stage might have no data\n",
    "if len(all_patches) == 0:\n",
    "    raise ValueError(\"No data loaded. Check your filepaths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 5. CNN Image conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patches_cnn = all_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 6. Array Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, patch_height, patch_width, n_features = all_patches.shape\n",
    "all_patches_flat = all_patches.reshape((n_samples, patch_height * patch_width * n_features)) #Image converted in to flate array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 7. Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_patches_flat, all_labels, test_size=0.3, random_state=42, stratify=all_labels) #Image flate converted for train the model\n",
    "\n",
    "\n",
    "# Split data and CNN conversion\n",
    "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(all_patches_cnn, all_labels, test_size=0.3, random_state=42, stratify=all_labels)\n",
    "\n",
    "# Data validation and Test Data\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)\n",
    "X_val_cnn, X_test_cnn, y_val_cnn, y_test_cnn = train_test_split(X_test_cnn, y_test_cnn, test_size=0.5, random_state=42, stratify=y_test_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 8. Data scalling and CNN image Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'data' directory exists\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train_cnn = X_train_cnn / 255.0\n",
    "X_val_cnn = X_val_cnn / 255.0\n",
    "X_test_cnn = X_test_cnn / 255.0\n",
    "\n",
    "#Data save\n",
    "np.save(\"data/X_train_ml.npy\", X_train)\n",
    "np.save(\"data/y_train_ml.npy\", y_train)\n",
    "np.save(\"data/X_val_ml.npy\", X_val)\n",
    "np.save(\"data/y_val_ml.npy\", y_val)\n",
    "np.save(\"data/X_test_ml.npy\", X_test)\n",
    "np.save(\"data/y_test_ml.npy\", y_test)\n",
    "\n",
    "np.save(\"data/X_train_cnn.npy\", X_train_cnn)\n",
    "np.save(\"data/y_train_cnn.npy\", y_train_cnn)\n",
    "np.save(\"data/X_val_cnn.npy\", X_val_cnn)\n",
    "np.save(\"data/y_val_cnn.npy\", y_val_cnn)\n",
    "np.save(\"data/X_test_cnn.npy\", X_test_cnn)\n",
    "np.save(\"data/y_test_cnn.npy\", y_test_cnn)\n",
    "\n",
    "joblib.dump(scaler, 'data/scaler.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
